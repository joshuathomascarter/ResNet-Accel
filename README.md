# ACCEL-v1: Sparse CNN Accelerator for FPGA

**A research FPGA accelerator for sparse neural networks targeting Zynq-7020.**  
Built from scratch (Sept–Dec 2025). Implements weight-stationary systolic arrays with BSR sparse format.

> **Status**: RTL complete, simulation verified. Python tooling functional. **C++ host driver in planning phase.**

---

## Performance Targets (Simulation-Based)

| Metric | Target | Notes |
|--------|--------|-------|
| **Peak Throughput** | 6.4 GOPS | 16×16 array @ 200 MHz (256 MACs/cycle) |
| **Sparse Speedup** | 6–9× | vs dense baseline at 70–90% sparsity |
| **Memory Reduction** | 9.7× | BSR format (118 KB vs 1.15 MB for MNIST FC1) |
| **INT8 Accuracy** | 98.7% | MNIST CNN, 0.2% degradation from FP32 |
| **Power Target** | 840 mW | Dual-clock + clock gating (vs 2.0 W baseline) |

*Hardware validation pending synthesis and FPGA deployment.*

---

## Key Features

### Hardware (RTL)
- **16×16 Weight-Stationary Systolic Array** — INT8×INT8→INT32 accumulation
- **BSR Sparse Format** — Block Sparse Row with hardware scheduler, skips zero blocks
- **Dual-Clock Architecture** — 50 MHz control / 200 MHz datapath
- **AXI4 Interface** — DMA for weights/activations, AXI-Lite for CSR control
- **Power Optimization** — Clock gating, zero-bypass MACs, multi-voltage support

### Software (Python — Current)
- **INT8 Quantization** — Per-channel quantization with calibration
- **BSR Export** — Convert dense weights to hardware-ready sparse format
- **Golden Models** — Bit-exact reference for verification
- **CocoTB Testbenches** — AXI protocol verification

### Software (C++ — Planned)
- **Zynq Host Driver** — Direct hardware control via `/dev/mem`
- **DMA Memory Manager** — Physically contiguous buffer allocation
- **BSR Packer** — High-performance sparse format conversion
- **ResNet-18 Inference** — Full model execution on FPGA

## Architecture Overview

```
┌──────────────────────────────────────────────────────────────────────┐
│                         ACCEL-v1 Architecture                        │
│                                                                      │
│  ┌────────────────┐                    ┌──────────────────────┐      │
│  │   Host (CPU)   │ <──AXI4-Lite CSR──>│   Control Logic      │      │
│  │                │                    │  • Scheduler (50MHz) │      │
│  │  • Configure   │                    │  • BSR Scheduler     │      │
│  │  • Start/Stop  │                    │  • DMA Controller    │      │
│  │  • Read Status │                    │  • Clock Gating      │      │
│  └────────┬───────┘                    └──────────┬───────────┘      │
│           │                                       │                  │
│           │ AXI4 Burst DMA (400 MB/s)             │ Control          │
│           ▼                                       ▼                  │
│  ┌────────────────────────────────────────────────────────┐          │
│  │              Memory Subsystem                          │          │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐     │          │
│  │  │ Act Buffer  │  │ Wgt Buffer  │  │ BSR Metadata│     │          │
│  │  │   (1 KB)    │  │   (1 KB)    │  │   Cache     │     │          │
│  │  └─────┬───────┘  └─────┬───────┘  └─────┬───────┘     │          │
│  └────────┼──────────────────┼────────────────┼───────────┘          │
│           │                  │                │                      │
│           └──────────┬───────┴────────────────┘                      │
│                      ▼                                               │
│  ┌────────────────────────────────────────────────────────┐          │
│  │         Systolic Array (16x16 PEs @ 200 MHz)           │          │
│  │  ┌───────┐  ┌───────┐     INT8 x INT8 -> INT32         │          │
│  │  │ PE    │──│ PE    │     Weight-Stationary Dataflow   │          │
│  │  │ MACx1 │  │ MACx1 │     Zero-Value Bypass            │          │
│  │  └───┬───┘  └───┬───┘                                  │          │
│  │      │          │                                      │          │
│  │  ┌───▼───┐  ┌───▼───┐                                  │          │
│  │  │ PE    │──│ PE    │     256 MACs/cycle @ 200 MHz     │          │
│  │  │ MACx1 │  │ MACx1 │     = 51.2 billion ops/s         │          │
│  │  └───────┘  └───────┘                                  │          │
│  └────────────────────────────────────────────────────────┘          │
│                      │                                               │
│                      ▼                                               │
│  ┌─────────────────────────────────────────────────────────┐         │
│  │              Result Accumulation                        │         │
│  │  • INT32 accumulators (overflow detection)              │         │
│  │  • Optional saturation                                  │         │
│  │  • AXI write-back to host memory                        │         │
│  └─────────────────────────────────────────────────────────┘         │
│                                                                      │
└──────────────────────────────────────────────────────────────────────┘
```

### Key Design Decisions

| Feature | Choice | Rationale |
|---------|--------|-----------|
| **Data Type** | INT8 | 4x memory reduction, 0.2% accuracy loss |
| **Array Size** | 16x16 PEs | Balanced area/performance for FPGA |
| **Block Size** | 16x16 | Matches systolic array tiling, sparse-friendly |
| **Dataflow** | Row-Stationary | Minimizes weight reloads, maximizes reuse |
| **Clock Gating** | BUFGCE primitives | 810 mW savings (40.5% power reduction) |
| **Sparse Format** | BSR | Hardware-friendly, sequential memory access |

## Project Structure

```
ACCEL-v1/                            # 20,675 total lines of code
├── rtl/                             # 6,875 lines of production RTL
│   ├── top/                         # Top-level modules
│   │   ├── accel_top.sv             # Main accelerator (100 MHz)
│   │   ├── accel_top_dual_clk.sv    # Dual-clock wrapper (Phase 5)
│   │   └── accel_top.upf            # Multi-voltage UPF
│   ├── systolic/                    # Compute core
│   │   ├── systolic_array_sparse.sv # Sparse 2x2 array
│   │   ├── pe.sv                    # Processing Element
│   │   └── mac8.sv                  # INT8 MAC w/ zero-bypass
│   ├── control/                     # Control logic
│   │   ├── scheduler.sv             # Tile scheduler (gated)
│   │   ├── bsr_scheduler.sv         # Sparse BSR FSM
│   │   ├── csr.sv                   # CSR registers (gated)
│   │   └── pulse_sync.sv            # CDC synchronizers
│   ├── dma/                         # DMA engines
│   │   ├── axi_dma_master.sv        # 400 MB/s burst DMA
│   │   └── bsr_dma.sv               # BSR metadata loader
│   └── buffer/                      # Memory subsystem
│       ├── act_buffer.sv            # 1 KB activation buffer
│       └── wgt_buffer.sv            # 1 KB weight buffer
│
├── accel/python/                    # 3,200 lines Python
│   ├── training/                    # INT8 training pipeline
│   │   └── mnist_cnn_int8.py        # 98.7% accuracy
│   ├── exporters/                   # BSR + INT8 exporters
│   ├── golden/                      # Bit-exact reference
│   └── tests/                       # 26 tests (100% passing)
│       ├── test_axi_dma.py          # DMA verification
│       └── test_stress.py           # 100 random matrices
│
├── docs/                            # 8,500 lines documentation
│   ├── architecture/                # Design specs
│   │   └── SPARSITY_FORMAT.md       # BSR format
│   ├── guides/                      # Implementation guides
│   │   ├── POWER_OPTIMIZATION_ADVANCED.md
│   │   └── QUANTIZATION_PRACTICAL.md
│   └── project/                     # Development logs
│
└── testbench/                       # 2,100 lines testbenches
    ├── cocotb/                      # Python co-simulation
    ├── verilator/                   # C++ testbenches
    └── unit/                        # Per-module tests
```

**Code Statistics**: 6,875 RTL lines | 26/26 tests passing | 0 lint errors

## Quick Start

### Prerequisites

```bash
# macOS
brew install verilator python numpy

# Ubuntu
sudo apt install verilator python3-numpy
```

### Build & Test

```bash
# Run all tests (34 tests)
./scripts/test.sh

# Build specific testbench
cd testbench && make accel_top_tb

# Run with waveform
./build/accel_top_tb && gtkwave build/waveforms/accel_top_tb.vcd
```

### FPGA Deployment (Zynq-7020)

```bash
# 1. Synthesize in Vivado
vivado -mode batch -source scripts/synthesize_vivado.tcl

# 2. Copy to PYNQ board
scp bitstream.bit xilinx@pynq:/home/xilinx/

# 3. Run Python driver
python3 accel/python/host/accel.py
```

## Engineering Journey: Struggles & Solutions

Building a sparse accelerator from scratch revealed several non-obvious challenges. This section documents the real engineering problems encountered and how they were solved.

### 1. BSR DMA Multi-Block Transfer Bug

**Problem**: Single-block transfers worked perfectly, but multi-block BSR matrices caused data corruption. The DMA would fetch Block 0 correctly, then garbage for subsequent blocks.

**Root Cause**: The `bsr_dma.sv` module incremented `blk_ptr` on every clock cycle during `STREAM` state, not just when `tready` was asserted. With backpressure from the systolic array, the pointer would advance 3-4 positions while data was stalled.

**Fix**:
```systemverilog
// BEFORE (buggy)
STREAM: begin
    blk_ptr <= blk_ptr + 1;  // Always increments!
    ...
end

// AFTER (correct)
STREAM: begin
    if (axis_tready) begin   // Only on handshake
        blk_ptr <= blk_ptr + 1;
    end
    ...
end
```

**Lesson**: AXI-Stream backpressure handling must be rigorous. Always gate state transitions on handshake signals.

### 2. 8x8 to 16x16 Systolic Scaling

**Problem**: Scaling the systolic array from 8x8 (64 PEs) to 16x16 (256 PEs) broke the BSR scheduler. Tests showed correct first-row computation, then all zeros.

**Root Cause**: The scheduler had hardcoded `3'd7` for the 8-cycle weight load count:
```systemverilog
if (load_cnt == 3'd7) begin  // Hardcoded for 8x8!
    state <= COMPUTE;
end
```
With 16x16 blocks, we needed 16 cycles, but `load_cnt` was only 3 bits wide.

**Fix**: Parameterized the scheduler with `BLOCK_SIZE`:
```systemverilog
parameter BLOCK_SIZE = 16;
localparam LOAD_CNT_MAX = BLOCK_SIZE - 1;
logic [4:0] load_cnt;  // 5 bits for 16

if (load_cnt == LOAD_CNT_MAX[4:0]) begin
    state <= COMPUTE;
end
```

**Lesson**: Never hardcode array dimensions. Use parameters consistently from top to bottom of the hierarchy.

### 3. Verilator Timing Simulation Mode

**Problem**: Pure SystemVerilog testbenches (no C++ harness) failed with "No C++ main()" error. Wanted self-contained `.sv` testbenches for simplicity.

**Root Cause**: Verilator 5.x changed the default behavior. Self-contained testbenches need explicit flags.

**Fix**: Add `--timing --main` flags:
```bash
verilator --sv --cc --exe --build --trace --timing --main \
    -Wall -Wno-fatal \
    -I rtl/... \
    testbench/sv/accel_top_tb_full.sv
```

**Lesson**: Track tool version changes. Verilator 5.x has breaking changes from 4.x.

### 4. CSR Register Edge Cases

**Problem**: 61% coverage seemed acceptable, but uncovered paths included critical error handling: writes to read-only registers, out-of-range addresses, malformed transactions.

**Root Cause**: Happy-path testing is easy. Error-path testing requires deliberate fault injection.

**Fix**: Added 12 targeted edge-case tests:
- Write to read-only STATUS register (should ignore)
- Read from undefined address 0x9999 (should return 0)
- Burst writes across register boundary
- Simultaneous read/write to same address

Coverage improved from 61% -> 71%.

**Lesson**: Coverage gaps often indicate missing error handling. Each uncovered line is a potential bug in production.

### 5. Output Accumulator Bank Swap Race

**Problem**: Double-buffered accumulator occasionally produced corrupted outputs when compute and DMA operated simultaneously.

**Root Cause**: Bank swap occurred mid-DMA-read. The read address was valid for Bank 0, but the swap switched to Bank 1 data.

**Fix**: Added `dma_busy` signal and gated swaps:
```systemverilog
wire can_swap = swap_request && !dma_busy && accumulation_done;

always_ff @(posedge clk) begin
    if (can_swap) begin
        active_bank <= ~active_bank;
    end
end
```

**Lesson**: Double-buffering requires careful handshaking. Both producer and consumer must agree on swap timing.

### 6. INT8 Quantization Overflow

**Problem**: Large activations caused overflow after ReLU, wrapping 130 -> -126 (signed INT8).

**Root Cause**: Accumulator was 32-bit signed, but quantization divided by scale then truncated to 8 bits without saturation.

**Fix**: Explicit saturation logic:
```systemverilog
wire signed [31:0] scaled = accumulator >>> scale_shift;
wire [7:0] saturated = (scaled > 127) ? 8'd127 :
                       (scaled < -128) ? 8'd128 :
                       scaled[7:0];
```

**Lesson**: Quantization is not just division. Saturation, rounding, and clipping are equally important.

## Documentation

| Document | Description |
|----------|-------------|
| [Architecture Overview](docs/architecture/ARCHITECTURE.md) | System design, dataflow, memory hierarchy |
| [BSR Format Spec](docs/architecture/SPARSITY_FORMAT.md) | Sparse format details, hardware FSM |
| [Power Optimization](docs/guides/POWER_OPTIMIZATION_ADVANCED.md) | 5-phase optimization (2.0W -> 840mW) |
| [Quantization Guide](docs/guides/QUANTIZATION_PRACTICAL.md) | INT8 training, per-channel quantization |
| [Simulation Guide](docs/guides/SIMULATION_GUIDE.md) | Verilator setup, testbench usage |
| [FPGA Deployment](docs/guides/FPGA_DEPLOYMENT.md) | Vivado synthesis, bitstream generation |
| [Verification Report](docs/verification/VERIFICATION.md) | Test coverage, CocoTB tests |
| [Project Timeline](docs/project/EXECUTION_SUMMARY.md) | 7-month development log |

## License

MIT License - See [LICENSE](LICENSE) for details.

## Contact

**Author**: Joshua Carter
**Email**: joshtcarter0710@gmail.com
**GitHub**: [@joshuathomascarter](https://github.com/joshuathomascarter)
**Repository**: [ACCEL-v1](https://github.com/joshuathomascarter/ACCEL-v1)

**Josh Carter**
MS Computer Engineering Candidate
December 2025

## References

### Academic Papers
- Y. Chen et al., "Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for CNNs" (ISCA 2016)
- S. Han et al., "EIE: Efficient Inference Engine on Compressed Deep Neural Networks" (ISCA 2016)
- N. P. Jouppi et al., "In-Datacenter Performance Analysis of a Tensor Processing Unit" (ISCA 2017)

### Technical Resources
- Xilinx UltraScale Architecture Clock Resources (UG472)
- AMBA AXI4 Specification (ARM IHI 0022E)
- Verilator User Guide (Version 5.0)
# ACCEL-v1: Sparse CNN Accelerator for FPGA
